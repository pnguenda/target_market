{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This ML script would not have been possible without inspiration from, github user ***'wiamsuri'*** and their project ***'cnn-image-classifier-keras'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "# from PIL import ImageFile\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [item.replace('resources/data_for_training_06/', '') for item in sorted(glob(\"resources/data_for_training_06/*/\"))]\n",
    "number_of_image_categories = len(image_names)\n",
    "print('%d image categories.' % number_of_image_categories)\n",
    "print('Three categories:')\n",
    "print(image_names[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    image_files = np.array(data['filenames'])\n",
    "    image_targets = np_utils.to_categorical(np.array(data['target']), number_of_image_categories)\n",
    "    return image_files, image_targets\n",
    "\n",
    "\n",
    "image_files, image_targets = load_dataset('resources/data_for_training_06/')\n",
    "\n",
    "trains_validate_files, test_files, trains_validate_targets, test_targets = \\\n",
    "    train_test_split(image_files, image_targets, test_size=0.2, random_state=42)\n",
    "\n",
    "train_files, valid_files, train_targets, valid_targets = \\\n",
    "    train_test_split(trains_validate_files, trains_validate_targets, test_size=0.25, random_state=42)\n",
    "\n",
    "image_names = [item for item in sorted(glob(\"resources/data_for_training_06/*/\"))]\n",
    "\n",
    "print('%s images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('%d training images.' % len(train_files))\n",
    "print('%d validation images.' % len(valid_files))\n",
    "print('%d test images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function for preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, grayscale=False, color_mode=\"rgb\", target_size=(500, 500), interpolation=\"nearest\")\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# ADJUST FILTER?\n",
    "model.add(Conv2D(filters=2, kernel_size=2, padding='same',\n",
    "                 activation='relu', input_shape=(500, 500, 3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=12, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with training and validating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.image_classifier.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=128, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# OPTIONAL WRITE HISTORY TO JSON\n",
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ in SAVED HISTORY\n",
    "history = history = pickle.load(open('trainHistoryDict', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_models/weights.best.image_classifier.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('saved_models/weights.best.image_classifier.hdf5')\n",
    "# model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model's accuracy\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir('test_imgs'):\n",
    "    img = plt.imread('test_imgs' + '/' + image)\n",
    "    resized_image = resize(img, (500,500,3))\n",
    "    predictions = model.predict(np.array([resized_image]))\n",
    "#     print(f'{image}:\\t {predictions}')\n",
    "    if image.split(\"_\")[0] == \"brick\":\n",
    "        print(image, predictions)\n",
    "#         print(f'{image}:\\t {round(100 * predictions[0][0])}%')\n",
    "\n",
    "# for image in os.listdir('test_imgs'):\n",
    "#     img = plt.imread('test_imgs' + '/' + image)\n",
    "#     resized_image = resize(img, (400,400,3))\n",
    "#     predictions = model.predict(np.array([resized_image]))\n",
    "# #     print(f'{image}:\\t {predictions}')\n",
    "#     if image.split(\"_\")[0] == \"brick\":\n",
    "# #         print(f'{image}:\\t {round(100 * predictions[0][0])}%')\n",
    "\n",
    "# for image in os.listdir('test_imgs'):\n",
    "#     img = plt.imread('test_imgs' + '/' + image)\n",
    "#     resized_image = resize(img, (400,400,3))\n",
    "#     predictions = model.predict(np.array([resized_image]))\n",
    "# #     print(f'{image}:\\t {predictions}')\n",
    "#     if image.split(\"_\")[0] == \"unknown\":\n",
    "# #         print(f'{image}:\\t {round(100 * predictions[0][0])}%')\n",
    "\n",
    "#['brick_10/', 'siding_20/', 'unknown_00/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = plt.imread('test_imgs/brick_5901.jpg')\n",
    "img = plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the predictions from least to greatest\n",
    "list_index = [0, 1, 2]\n",
    "x = predictions\n",
    "\n",
    "for i in range(3):\n",
    "  for j in range(3):\n",
    "    if x[0][list_index[i]] > x[0][list_index[j]]:\n",
    "      temp = list_index[i]\n",
    "      list_index[i] = list_index[j]\n",
    "      list_index[j] = temp\n",
    "\n",
    "#Show the sorted labels in order\n",
    "print(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history: \n",
    "plt.plot(history['loss'], label='(training data)')\n",
    "plt.plot(history['val_loss'], label='(validation data)')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
